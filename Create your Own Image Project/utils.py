# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dlOPp2BL0zRr3gZBHyTyE8xp6Da6kyQJ
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
from torch import nn, optim
from torch.autograd import Variable
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from collections import OrderedDict
import json
from PIL import Image
import argparse

parser = argparse.ArgumentParser(description='Train a neural network on image classification data')
parser.add_argument('--data_dir', type=str, default='./flowers', help='Directory of the dataset')

args = parser.parse_args()

arch = {"vgg16": 25088, "alexnet": 9016}

def create_transforms():
    train_transforms = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(p=0.9),
        transforms.RandomRotation(20),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    val_test_transforms = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    return train_transforms, val_test_transforms

def load_datasets(root, train_transforms, val_test_transforms):
    train_dir = f'{root}/train'
    valid_dir = f'{root}/valid'
    test_dir = f'{root}/test'

    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)
    val_data = datasets.ImageFolder(valid_dir, transform=val_test_transforms)
    test_data = datasets.ImageFolder(test_dir, transform=val_test_transforms)

    return train_data, val_data, test_data

def create_dataloaders(train_data, val_data, test_data, batch_size=64):
    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)

    return train_loader, val_loader, test_loader

def load_data(root):
    with open('cat_to_name.json', 'r') as f:
        cat_to_name = json.load(f, strict =False)

    train_transforms, val_test_transforms = create_transforms()
    train_data, val_data, test_data = load_datasets(root, train_transforms, val_test_transforms)
    train_loader, val_loader, test_loader = create_dataloaders(train_data, val_data, test_data)

    return train_loader, val_loader, test_loader, train_data