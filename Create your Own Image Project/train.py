# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/144TWpAkgHfeQ-u2TI3QbMFUFz8LSf3-s
"""

import numpy as np
import argparse
import torch
from torch import nn, optim
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from torch.autograd import Variable
from collections import OrderedDict
import matplotlib.pyplot as plt
import json
from PIL import Image
import utils
import model_data

parser = argparse.ArgumentParser(
    description = 'Parser for train.py'
)
parser.add_argument('--data_dir', action="store", default="./flowers/")
parser.add_argument('--save_dir', action="store", default="./checkpoint.pth")
parser.add_argument('--arch', action="store", default="vgg16")
parser.add_argument('--learning_rate', action="store", type=float,default=0.001)
parser.add_argument('--hidden_units', action="store", dest="hidden_units", type=int, default=512)
parser.add_argument('--epochs', action="store", default=5, type=int)
parser.add_argument('--dropout', action="store", type=float, default=0.2)
parser.add_argument('--device', type=str, default='cuda', choices=['cpu', 'cuda'], help='Device to use for training: "cpu" or "cuda"')



args = parser.parse_args()
your_data = args.data_dir
path = args.save_dir
lr = args.learning_rate
the_model = args.arch
hidden_units = args.hidden_units
device = args.device
epochs = args.epochs
dropout = args.dropout

device = torch.device(args.device if torch.cuda.is_available() else "cpu")


def main():
    train_load, val_load, test_load, train_data = utils.load_data(your_data)
    model, criterion,optimizer = model_data.neural_network(the_model,dropout,hidden_units,lr,device)

    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

    print_every = 30
    best_valid_loss = float('inf')
    patience = 2
    patience_counter = 0

    for e in range(epochs):
        running_loss = 0
        steps = 0
        model.train()
        for inputs, labels in train_load:
            steps += 1
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

            if steps % print_every == 0:
                model.eval()
                valid_loss = 0
                accuracy = 0
                with torch.no_grad():
                    for inputs, labels in val_load:
                        inputs, labels = inputs.to(device), labels.to(device)
                        log_ps = model(inputs)
                        batch_loss = criterion(log_ps, labels)
                        valid_loss += batch_loss.item()

                        ps = torch.exp(log_ps)
                        top_p, top_class = ps.topk(1, dim=1)
                        equals = top_class == labels.view(*top_class.shape)
                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()

                current_loss = running_loss / print_every
                current_valid_loss = valid_loss / len(val_load)
                current_accuracy = accuracy / len(val_load) * 100

                print(f"Epoch {e+1}/{epochs}.... "
                      f"Loss: {current_loss:.3f}.... "
                      f"Validation Loss: {current_valid_loss:.3f}.... "
                      f"Accuracy: {current_accuracy:.3f}%")
                running_loss = 0

                if current_valid_loss < best_valid_loss:
                    best_valid_loss = current_valid_loss
                    patience_counter = 0
                else:
                    patience_counter += 1
                    if patience_counter > patience:
                        print("Stopping early due to no improvement in validation loss")
                        break

                model.train()

        scheduler.step()


    model.class_to_idx =  train_data.class_to_idx
    torch.save({'structure' :the_model,
                'hidden_units':hidden_units,
                'dropout':dropout,
                'learning_rate':lr,
                'no_of_epochs':epochs,
                'state_dict':model.state_dict(),
                'class_to_idx':model.class_to_idx},
                path)
    print("Saved checkpoint!")
if __name__ == "__main__":
    main()

"""References

https://github.com/vishalnarnaware/Create-your-own-Image-Classifier/blob/master/train.py

"""

